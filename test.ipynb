{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "hiragana = dict(a='あ',i='い',u='う',e='え',o='お',\n",
    "                    ka='か',ki='き',ku='く',ke='け',ko='こ',\n",
    "                    sa='さ',si='し',su='す',se='せ',so='そ',\n",
    "                    ta='た',ti='ち',tu='つ',te='て',to='と',\n",
    "                    na='な',ni='に',nu='ぬ',ne='ね',no='の',\n",
    "                    ha='は',hi='ひ',hu='ふ',he='へ',ho='ほ',\n",
    "                    ma='ま',mi='み',mu='む',me='め',mo='も',\n",
    "                    ya='ya',yu='ゆ',yo='よ',\n",
    "                    wa='わ',wo='を',n='ん')\n",
    "key = random.choice(list(hiragana.keys()))\n",
    "output = f\"請寫出{key}的假名\"\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = 'm.mp3'\n",
    "s3.rsplit('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_options=('あ','い','う','え','お',\n",
    "                        'か','き','く','け','こ',\n",
    "                        'さ','し','す','せ','そ',\n",
    "                        'た','ち','つ','て','と',\n",
    "                        'な','に','ぬ','ね','の',\n",
    "                        'は','ひ','ふ','へ','ほ',\n",
    "                        'ま','み','む','め','も',\n",
    "                        'や','ゆ','よ',\n",
    "                        'ら','り','る','れ','ろ',\n",
    "                        'わ','を','ん')\n",
    "prediction_options[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i='[1,2,3,4,5,6,7,8]'\n",
    "b=eval(i)\n",
    "b[0]=4\n",
    "c=str(b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0, 0, -1, 0, 0, 0, -1, 0, 0]\n",
    "rate = min(a)\n",
    "index = a.index(rate)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tflite_support.task'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Imports\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_support\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m \u001b[39mimport\u001b[39;00m audio\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_support\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m \u001b[39mimport\u001b[39;00m core\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtflite_support\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtask\u001b[39;00m \u001b[39mimport\u001b[39;00m processor\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tflite_support.task'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from tflite_support.task import audio\n",
    "from tflite_support.task import core\n",
    "from tflite_support.task import processor\n",
    "\n",
    "# Initialization\n",
    "base_options = core.BaseOptions(file_name='metadate.tflite')\n",
    "classification_options = processor.ClassificationOptions(max_results=2)\n",
    "options = audio.AudioClassifierOptions(base_options=base_options, classification_options=classification_options)\n",
    "classifier = audio.AudioClassifier.create_from_options(options)\n",
    "\n",
    "# Alternatively, you can create an audio classifier in the following manner:\n",
    "# classifier = audio.AudioClassifier.create_from_file(model_path)\n",
    "\n",
    "# Run inference\n",
    "audio_file = audio.TensorAudio.create_from_wav_file('a.wav', classifier.required_input_buffer_size)\n",
    "audio_result = classifier.classify(audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
